{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8850ea-4616-4418-ab52-7a7606d90696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c381c1-cd50-4edc-a11d-60d0da3d5ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "pip install --quiet tqdm huggingface_hub aiohttp nest_asyncio psycopg2-binary uuid-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1761aed-9511-46b3-b675-91c6a7eac01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "import datetime as dt\n",
    "from itertools import islice\n",
    "import json\n",
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import nest_asyncio\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from typing import Any, Optional, Union\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_object_dtype\n",
    "import psycopg2\n",
    "import pyspark\n",
    "from pyspark import sql as pysql\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, ShortType, IntegerType, LongType, DoubleType, BooleanType,\n",
    "    TimestampType, ArrayType, MapType\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from uuid_utils import uuid7\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85ddc65-1462-47e2-a308-c2e1d5a8349e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ENCODING_TYPE = 'utf-8-sig'\n",
    "BASE = \"https://huggingface.co\"\n",
    "HF_READ_TOKEN = \"YOUR_TOKEN\"\n",
    "HF_WRITE_TOKEN = \"YOUR_TOKEN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970a864a-1a32-4929-b29e-3f930fb64674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Set Schema Using Pyspark StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02dea316-f4e9-4ce5-b364-5e4e74ee94bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2-1. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f26c7be6-465e-4844-b9cf-a501add50606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "meta_schema = StructType([\n",
    "    StructField(\"id\",                   StringType(),       False), # PK, NOT NULL\n",
    "    StructField(\"hexid\",                StringType(),       True),  # CHAR(24)\n",
    "    StructField(\"sha\",                  StringType(),       True),  # CHAR(40)\n",
    "    StructField(\"author\",               StringType(),       True),  # \n",
    "    StructField(\"private\",              BooleanType(),      True),  # \n",
    "    StructField(\"disabled\",             BooleanType(),      True),  # \n",
    "    StructField(\"gated\",                StringType(),       True),  #   \n",
    "    StructField(\"pipeline_tag\",         StringType(),       True),  # \n",
    "    StructField(\"library_name\",         StringType(),       True),  # \n",
    "    StructField(\"tags\",                 StringType(),       True),  # '[\"a\",\"b\"]' 같은 문자열\n",
    "    StructField(\"likes\",                DoubleType(),       True),  # \n",
    "    StructField(\"downloads\",            DoubleType(),       True),  # \n",
    "    StructField(\"trending_score\",       DoubleType(),       True),  # \n",
    "    StructField(\"created_at\",           TimestampType(),    True),  # \n",
    "    StructField(\"last_modified\",        TimestampType(),    True),  # \n",
    "    StructField(\"config\",               StringType(),       True),  # JSON 문자열\n",
    "    StructField(\"card_data\",            StringType(),       True),  # JSON 문자열\n",
    "    StructField(\"safetensors\",          StringType(),       True),  # JSON 문자열\n",
    "    StructField(\"spaces\",               StringType(),       True),  # '[\"a\",\"b\"]' 같은 문자열\n",
    "    StructField(\"transformers_info\",    StringType(),       True),  # JSON 문자열\n",
    "    StructField(\"used_storage\",         DoubleType(),       True),  # \n",
    "    StructField(\"readme\",               StringType(),       True),  # \n",
    "\n",
    "    StructField(\"model_index\",          StringType(),       True),  # '[\"a\",\"b\"]' 같은 문자열\n",
    "    StructField(\"gguf\",                 StringType(),       True),  # \n",
    "    StructField(\"inference\",            StringType(),       True),  # \n",
    "    StructField(\"mask_token\",           StringType(),       True),  # \n",
    "    StructField(\"widget_data\",          StringType(),       True),  # \n",
    "    StructField(\"security_repo_status\", StringType(),       True)   # \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e9ca8f1-6fa1-4f6d-bbb9-cd1e60c04d46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2-2. Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f0528d-5717-486c-9e0c-c7693df15832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_schema = StructType([\n",
    "    StructField(\"uuid7\",           StringType(),    False), # PK, NOT NULL\n",
    "    StructField(\"model_id\",        StringType(),    False), # FK, NOT NULL\n",
    "    StructField(\"type\",            StringType(),    True),  # \n",
    "    StructField(\"oid\",             StringType(),    True),  # \n",
    "    StructField(\"size\",            LongType(),      True),  # \n",
    "    StructField(\"path\",            StringType(),    True),  # \n",
    "    StructField(\"lfs_oid\",         StringType(),    True),  # \n",
    "    StructField(\"lfs_size\",        DoubleType(),    True),  # \n",
    "    StructField(\"lfs_pointersize\", DoubleType(),    True),  # \n",
    "    StructField(\"xethash\",         StringType(),    True)   # \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd0a904-5965-412a-8e83-47181121abfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2-3. Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d42216b-deaa-4cfc-afc5-dfec486abfe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comu_schema = StructType([\n",
    "    StructField(\"uuid7\",                        StringType(),       False), # PK, NOT NULL\n",
    "    StructField(\"model_id\",                     StringType(),       False), # FK, NOT NULL\n",
    "    StructField(\"num\",                          LongType(),         True),  # \n",
    "    StructField(\"title\",                        StringType(),       True),  # \n",
    "    StructField(\"status\",                       StringType(),       True),  # \n",
    "    StructField(\"created_at\",                    TimestampType(),    True),  # \n",
    "    StructField(\"is_pull_request\",                BooleanType(),      True),  # \n",
    "    StructField(\"num_comments\",                  LongType(),         True),  # \n",
    "    StructField(\"top_reactions\",                 StringType(),       True),  # JSON 문자열\n",
    "    StructField(\"num_reaction_users\",             LongType(),         True),  # \n",
    "    StructField(\"pinned\",                       BooleanType(),      True),  # \n",
    "    StructField(\"author_id\",                   StringType(),       True),  # CHAR(24)\n",
    "    StructField(\"author_avatar_url\",             StringType(),       True),  # \n",
    "    StructField(\"author_fullname\",              StringType(),       True),  # \n",
    "    StructField(\"author_name\",                  StringType(),       True),  # \n",
    "    StructField(\"author_type\",                  StringType(),       True),  # \n",
    "    StructField(\"author_ispro\",                 BooleanType(),      True),  # \n",
    "    StructField(\"author_ishf\",                  BooleanType(),      True),  # \n",
    "    StructField(\"author_ishf_admin\",             BooleanType(),      True),  # \n",
    "    StructField(\"author_ismod\",                 BooleanType(),      True),  # \n",
    "    StructField(\"repo_name\",                    StringType(),       True),  # \n",
    "    StructField(\"repo_type\",                    StringType(),       True),  # \n",
    "    StructField(\"repo_owner_name\",               StringType(),       True),  # \n",
    "    StructField(\"repo_owner_isparticipating\",    BooleanType(),      True),  # \n",
    "    StructField(\"repo_owner_type\",               StringType(),       True),  # \n",
    "    StructField(\"repo_owner_isdiscussion_author\", BooleanType(),      True),  # \n",
    "    StructField(\"author_follower_count\",         DoubleType(),       True),  # \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a49456f-546c-4240-8d76-262dba27b51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Create PostgreSQL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2509fd0-6ddb-4e03-a719-bf0fffada11a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SCHEMA_LEVEL = \"bronze\"\n",
    "META_TABLE_NAME = \"brz_hf_meta\"\n",
    "FILE_TABLE_NAME = \"brz_hf_files\"\n",
    "COMU_TABLE_NAME = \"brz_hf_community\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e0e17c-7d52-4348-adc5-554667a5062e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"HOST\",\n",
    "    port=\"PORT\",\n",
    "    dbname=\"DB_NAME\",\n",
    "    user=\"USER_NAME\",\n",
    "    password=\"PASSWORD\"\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5977b8eb-c0ba-444d-8556-8166e7ed0411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 기존 테이블 드롭 (CASCADE 포함)\n",
    "cur.execute(f\"DROP TABLE IF EXISTS {SCHEMA_LEVEL}.{META_TABLE_NAME} CASCADE;\")\n",
    "cur.execute(f\"DROP TABLE IF EXISTS {SCHEMA_LEVEL}.{FILE_TABLE_NAME} CASCADE;\")\n",
    "cur.execute(f\"DROP TABLE IF EXISTS {SCHEMA_LEVEL}.{COMU_TABLE_NAME} CASCADE;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d92e71e3-c054-45b4-85fb-eda34bec2e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-1. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fd0b4fa-89c5-42cf-b752-ba65d7bb776a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_LEVEL}.{META_TABLE_NAME} (\n",
    "  id                   text NOT NULL PRIMARY KEY,\n",
    "  hexid                text,\n",
    "  sha                  text,\n",
    "  author               text,\n",
    "  private              boolean,\n",
    "  disabled             boolean,\n",
    "  gated                text,\n",
    "  pipeline_tag         text,\n",
    "  library_name         text,\n",
    "  tags                 text ,\n",
    "  likes                double precision,\n",
    "  downloads            double precision,\n",
    "  trending_score       double precision,\n",
    "  created_at           timestamptz,\n",
    "  last_modified        timestamptz,\n",
    "  config               text,\n",
    "  card_data            text,\n",
    "  safetensors          text,\n",
    "  spaces               text,\n",
    "  transformers_info    text,\n",
    "  used_storage         double precision,\n",
    "  readme               text,\n",
    "  model_index          text,\n",
    "  gguf                 text,\n",
    "  inference            text,\n",
    "  mask_token           text,\n",
    "  widget_data          text,\n",
    "  security_repo_status text\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0058ef4d-6df3-480e-b122-3f58e12f9c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-2. Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517226b0-7056-426b-8cee-e9f9b4550497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_LEVEL}.{FILE_TABLE_NAME} (\n",
    "    uuid7           TEXT NOT NULL PRIMARY KEY,\n",
    "    model_id        TEXT NOT NULL,\n",
    "    type            TEXT,\n",
    "    oid             TEXT,\n",
    "    size            BIGINT,\n",
    "    path            TEXT,\n",
    "    lfs_oid         TEXT,\n",
    "    lfs_size        DOUBLE PRECISION,\n",
    "    lfs_pointersize DOUBLE PRECISION,\n",
    "    xethash         TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# -- FK 정의 (모델 메타 테이블과 연결)\n",
    "#     CONSTRAINT fk_hfmeta\n",
    "#         FOREIGN KEY (model_id)\n",
    "#         REFERENCES {SCHEMA_LEVEL}.{META_TABLE_NAME} (id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9256a34d-ad3d-482e-a769-30e5b0becb6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-3. Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a1789f-8769-478b-a7c0-52ffc1e81321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_LEVEL}.{COMU_TABLE_NAME} (\n",
    "    uuid7                           TEXT NOT NULL PRIMARY KEY,\n",
    "    model_id                        TEXT NOT NULL,\n",
    "    num                             BIGINT,\n",
    "    title                           TEXT,\n",
    "    status                          TEXT,\n",
    "    created_at                       TIMESTAMPTZ,\n",
    "    is_pull_request                   BOOLEAN,\n",
    "    num_comments                     BIGINT,\n",
    "    top_reactions                    TEXT,\n",
    "    num_reaction_users                BIGINT,\n",
    "    pinned                          BOOLEAN,\n",
    "    author_id                      TEXT,\n",
    "    author_avatar_url                TEXT,\n",
    "    author_fullname                 TEXT,\n",
    "    author_name                     TEXT,\n",
    "    author_type                     TEXT,\n",
    "    author_ispro                    BOOLEAN,\n",
    "    author_ishf                     BOOLEAN,\n",
    "    author_ishf_admin                BOOLEAN,\n",
    "    author_ismod                    BOOLEAN,\n",
    "    repo_name                       TEXT,\n",
    "    repo_type                       TEXT,\n",
    "    repo_owner_name                  TEXT,\n",
    "    repo_owner_isparticipating       BOOLEAN,\n",
    "    repo_owner_type                  TEXT,\n",
    "    repo_owner_isdiscussion_author    BOOLEAN,\n",
    "    author_follower_count            DOUBLE PRECISION    \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# -- FK 정의 (모델 메타 테이블과 연결)\n",
    "#     CONSTRAINT fk_hfmeta\n",
    "#         FOREIGN KEY (model_id)\n",
    "#         REFERENCES {SCHEMA_LEVEL}.{META_TABLE_NAME} (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c34abd-4df2-4589-9158-9306f4878f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5091735938707682>, line 1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
       "\u001b[1;32m      2\u001b[0m cur\u001b[38;5;241m.\u001b[39mclose()\n",
       "\u001b[1;32m      3\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
       "\n",
       "\u001b[0;31mInterfaceError\u001b[0m: connection already closed"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "InterfaceError",
        "evalue": "connection already closed"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>InterfaceError</span>: connection already closed"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
        "File \u001b[0;32m<command-5091735938707682>, line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m      2\u001b[0m cur\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      3\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
        "\u001b[0;31mInterfaceError\u001b[0m: connection already closed"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5fc834-008a-459c-9da1-18ffde39c0c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. INSERT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9e82eae-fec9-4fa4-9a74-b28206a507a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def insert_data(\n",
    "    data: Union[pd.DataFrame, pyspark.sql.DataFrame],\n",
    "    schema: str,\n",
    "    table: str,\n",
    "    mode: str = \"overwrite\"\n",
    ") -> None:\n",
    "    # spark 데이터프레임 생성\n",
    "    columns = list(data.columns)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # data = spark.createDataFrame(data, schema=columns)\n",
    "        data = spark.createDataFrame(data)\n",
    "    \n",
    "    # 인증 정보 하드코딩\n",
    "    jdbc_user = \"USER_NAME\"\n",
    "    jdbc_pass = \"PASSWORD\"\n",
    "\n",
    "    # 연결 문자열 하드코딩\n",
    "    host = \"HOST\"\n",
    "    port = \"PORT\"\n",
    "    jdbc_url = f\"jdbc:postgresql://{host}:{port}/postgres\"\n",
    "    table_lc = table.lower()\n",
    "\n",
    "    if mode == \"upsert\":\n",
    "        staging = f\"{table_lc}_stg\"\n",
    "\n",
    "        # 1) 스테이징에 덮어쓰기 적재\n",
    "        data.write.format(\"jdbc\").mode(\"overwrite\").options(\n",
    "            url=jdbc_url,\n",
    "            user=jdbc_user,\n",
    "            password=jdbc_pass,\n",
    "            dbtable=f\"{schema}.{staging}\",\n",
    "            truncate=True,      # 데이터만 비움\n",
    "            batchsize=1000\n",
    "        ).save()\n",
    "\n",
    "        # 2) ON CONFLICT 업서트\n",
    "        cols = [f'\"{c}\"' for c in data.columns]\n",
    "        col_list = \", \".join(cols)\n",
    "        key_list = \", \".join([f'\"{k}\"' for k in (\"uuid7\",)])\n",
    "        update_cols = [c for c in data.columns if c not in (\"uuid7\",)]\n",
    "        set_clause = \", \".join([f'\"{c}\"=EXCLUDED.\"{c}\"' for c in update_cols]) or \"NOTHING\"\n",
    "\n",
    "        sql = f\"\"\"\n",
    "        INSERT INTO {schema}.{table_lc} ({col_list})\n",
    "        SELECT {col_list} FROM {schema}.{staging}\n",
    "        ON CONFLICT ({key_list}) DO UPDATE SET\n",
    "        {set_clause};\n",
    "        \"\"\"\n",
    "\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"HOST\",\n",
    "            port=\"PORT\",\n",
    "            dbname=\"postgres\",\n",
    "            user=jdbc_user,\n",
    "            password=jdbc_pass\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            cur.execute(f'DROP TABLE IF EXISTS {schema}.{staging};')\n",
    "        conn.close()\n",
    "\n",
    "    else:\n",
    "        data.write.format(\"jdbc\").mode(mode).options(\n",
    "            url=jdbc_url,\n",
    "            user=jdbc_user,\n",
    "            password=jdbc_pass,\n",
    "\n",
    "            # 가끔 테이블 이름을 대소문자 혼용하여 인자로 던져주는 경우를 대비한 코드\n",
    "            # PostgreSQL의 테이블은 언제나 소문자만 사용함\n",
    "            dbtable=f\"{schema}.{table_lc}\",\n",
    "\n",
    "            # overwrite일 때 DROP 후 CREATE가 아니라, TRUNCATE TABLE로 데이터만 비움\n",
    "            # truncate=True,\n",
    "\n",
    "            # 대량 적재 튜닝: INSERT할 때 한 번에 몇 행씩 묶어서 넣을지\n",
    "            batchsize=1000,\n",
    "\n",
    "            # 스키마 적재 튜닝: INSERT시 JDBC는 모든 문자열 컬럼에 대해 setString() 함수를 사용해서, 자동으로 PosgreSQL에 text로 적재함\n",
    "            # 이 옵션을 사용하면 unspecified로 넘겨 PostgreSQL 테이블의 스키마를 확인하고, 해당 스키마에 맞게끔 캐스팅함\n",
    "            # 대신 넣으려는 데이터와 테이블의 스키마를 정확히 일치시켜야 함. 그렇지 않으면 에러가 발생함\n",
    "            # 에러가 발생하는 경우 그냥 주석처리하거나, PostgreSQL 테이블 스키마를 TEXT로 전부 바꾸면 해결\n",
    "            # stringtype=\"unspecified\"\n",
    "        ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea6d3f75-c302-4988-b5be-9a686e9061ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4-1. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33f739a-a036-47eb-b02a-23518ed450bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/2 [00:00<?, ?it/s]\r 50%|█████     | 1/2 [01:14<01:14, 74.91s/it]\r100%|██████████| 2/2 [02:12<00:00, 64.93s/it]\r100%|██████████| 2/2 [02:12<00:00, 66.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# tmp_df = pd.read_csv('hf_metadata.csv', encoding=ENCODING_TYPE)\n",
    "# tmp_df[\"created_at\"] = pd.to_datetime(tmp_df[\"created_at\"], utc=True, errors=\"coerce\")\n",
    "# tmp_df[\"last_modified\"] = pd.to_datetime(tmp_df[\"last_modified\"], utc=True, errors=\"coerce\")\n",
    "# # tmp_df[\"model_index\"] = tmp_df[\"model_index\"].map(lambda x: list(x) if isinstance(x, str) else x)\n",
    "# tmp_df[\"likes\"] = tmp_df[\"likes\"].fillna(0).astype(\"int64\")\n",
    "# tmp_df[\"downloads\"] = tmp_df[\"downloads\"].fillna(0).astype(\"int64\")\n",
    "# tmp_df[\"used_storage\"] = tmp_df[\"used_storage\"].fillna(0).astype(\"int64\")\n",
    "# for c in tmp_df.columns:\n",
    "#     tmp_df[c] = tmp_df[c].where(pd.notna(tmp_df[c]), None)\n",
    "\n",
    "# # 특정 테이블에 데이터를 삽입하는 코드\n",
    "# # mode 종류: overwrite, append, ignore, error\n",
    "# insert_data(\n",
    "#     data=spark.createDataFrame(tmp_df, schema=meta_schema),\n",
    "#     schema=SCHEMA_LEVEL,\n",
    "#     table=META_TABLE_NAME,\n",
    "#     mode=\"overwrite\"\n",
    "# )\n",
    "\n",
    "for i in tqdm(range(1, 21 + 1)):\n",
    "    tmp_df = pd.read_csv(f'split/hf_metadata_{i}.csv', encoding=ENCODING_TYPE, low_memory=False).drop_duplicates(subset=['id'])\n",
    "    tmp_df[\"created_at\"] = pd.to_datetime(tmp_df[\"created_at\"], utc=True, errors=\"coerce\")\n",
    "    tmp_df[\"last_modified\"] = pd.to_datetime(tmp_df[\"last_modified\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    # 특정 테이블에 데이터를 삽입하는 코드\n",
    "    # mode 종류: overwrite, append, ignore, error, upsert(user definition)\n",
    "    insert_data(\n",
    "        data=spark.createDataFrame(tmp_df, schema=meta_schema),\n",
    "        schema=SCHEMA_LEVEL,\n",
    "        table=META_TABLE_NAME,\n",
    "        mode=\"upsert\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87f02d98-1336-41e8-9b05-ad30b1d5e1fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4-2. Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56c2c42-e288-4cf9-9a77-3dea46341464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(1, 168 + 1)):\n",
    "    tmp_df = pd.read_csv(f'split/hf_files_{i}.csv', encoding=ENCODING_TYPE, low_memory=False)\n",
    "    tmp_df = tmp_df[tmp_df['path'].notna()]\n",
    "\n",
    "    tmp_df[\"uuid7\"] = [str(uuid7()) for _ in range(len(tmp_df))]\n",
    "    cols = [\"uuid7\"] + [c for c in tmp_df.columns if c != \"uuid7\"]\n",
    "    tmp_df = tmp_df[cols].rename(columns={\"lfs_pointerSize\": \"lfs_pointersize\", \"xetHash\": \"xethash\"})\n",
    "\n",
    "    # 특정 테이블에 데이터를 삽입하는 코드\n",
    "    # mode 종류: overwrite, append, ignore, error\n",
    "    insert_data(\n",
    "        data=spark.createDataFrame(tmp_df, schema=file_schema),\n",
    "        schema=SCHEMA_LEVEL,\n",
    "        table=FILE_TABLE_NAME,\n",
    "        mode=\"append\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af60382-8635-4a52-922e-fdb72c5fcfb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4-3. Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ec9de29-61f3-4f03-b3d0-addcde5cd65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(tmp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df[\"created_at\"] = pd.to_datetime(tmp_df[\"created_at\"], utc=True, errors=\"coerce\")\n",
    "    tmp_df[[\"author_ispro\", \"author_ishf\", \"author_ishf_admin\", \"author_ismod\"]] = \\\n",
    "        tmp_df[[\"author_ispro\", \"author_ishf\", \"author_ishf_admin\", \"author_ismod\"]].fillna(False).astype(bool)\n",
    "    tmp_df[\"uuid7\"] = [str(uuid7()) for _ in range(len(tmp_df))]\n",
    "\n",
    "    # before_cols = tmp_df.columns.tolist()\n",
    "    # after_cols = [\n",
    "    #     \"uuid\", \"model_id\", \"num\", \"title\", \"status\" ,\"created_at\", \"is_pull_request\", \"num_comments\", \"top_reactions\", 'num_reaction_users' ,\"pinned\",\n",
    "    #     \"author_id\", \"author_avatar_url\", \"author_fullname\", \"author_name\", \"author_type\", \"author_ispro\", \"author_ishf\", \"author_ishf_admin\", \"author_ismod\", \n",
    "    #     \"author_follower_count\",\n",
    "    #     \"repo_name\", \"repo_type\", \"repo_owner_name\", \"repo_owner_isparticipating\", \"repo_owner_type\", \"repo_owner_isdiscussion_author\",\n",
    "    # ]\n",
    "    # rename_dict = dict(zip(before_cols, after_cols))\n",
    "    # tmp_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    reindex_cols = [\n",
    "        \"uuid7\", \"model_id\", \"num\", \"title\", \"status\" ,\"created_at\", \"is_pull_request\", \"num_comments\", \"top_reactions\", 'num_reaction_users' ,\"pinned\",\n",
    "        \"author_id\", \"author_avatar_url\", \"author_fullname\", \"author_name\", \"author_type\", \"author_ispro\", \"author_ishf\", \"author_ishf_admin\", \"author_ismod\", \n",
    "        \"repo_name\", \"repo_type\", \"repo_owner_name\", \"repo_owner_isparticipating\", \"repo_owner_type\", \"repo_owner_isdiscussion_author\",\n",
    "        \"author_follower_count\",\n",
    "    ]\n",
    "    tmp_df = tmp_df.reindex(columns=reindex_cols).where(pd.notna(tmp_df), None)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c09e4205-6a5e-41e0-ad66-fba636724488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/4 [00:00<?, ?it/s]\r 25%|██▌       | 1/4 [00:12<00:38, 12.80s/it]\r 50%|█████     | 2/4 [00:24<00:23, 11.96s/it]\r 75%|███████▌  | 3/4 [00:35<00:11, 11.90s/it]\r100%|██████████| 4/4 [00:39<00:00,  8.60s/it]\r100%|██████████| 4/4 [00:39<00:00,  9.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, 4 + 1)):\n",
    "    tmp_df = pd.read_csv(f'split/hf_community_{i}.csv', encoding=ENCODING_TYPE, low_memory=False)\n",
    "    tmp_df = preprocessing(tmp_df)\n",
    "\n",
    "    # 특정 테이블에 데이터를 삽입하는 코드\n",
    "    # mode 종류: overwrite, append, ignore, error\n",
    "    insert_data(\n",
    "        data=spark.createDataFrame(tmp_df, schema=comu_schema),\n",
    "        schema=SCHEMA_LEVEL,\n",
    "        table=COMU_TABLE_NAME,\n",
    "        mode=\"append\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82a0add0-9af0-4305-975d-cd87f6f34c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5091735938707663,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "데이터베이스 넣어넣어",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
