{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b46c89-8378-480f-bded-055613b4e30e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 0. JDBC 사용해서 DB에 적재하는 코드 두고 갑니다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c67c8062-e5fb-4a67-9ca5-83e770ab1361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-1. 필요한 라이브러리 설치 및 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "035b0e0c-8bb6-4d98-82f0-1cdea32bcdc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sh\n",
    "# pip install --quiet psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d74a4f-ee02-42bd-9631-abee01250f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting sqlalchemy\n  Using cached sqlalchemy-2.0.43-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\nCollecting typing-extensions>=4.6.0\n  Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nCollecting greenlet>=1\n  Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\nInstalling collected packages: typing-extensions, greenlet, sqlalchemy\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-604df710-fc7a-4de4-8e65-ce48b9582ce1\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\nSuccessfully installed greenlet-3.2.4 sqlalchemy-2.0.43 typing-extensions-4.15.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d125afe9-ab71-4577-8571-cb7d733e43b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7b9adaf-b9e2-416e-bdb1-1888946c5d52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pyspark\n",
    "from pyspark import sql as pysql\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, ShortType, IntegerType, LongType, DoubleType, BooleanType,\n",
    "    TimestampType, ArrayType, MapType\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00b227e-3cb6-4d7e-8931-027062725a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-2. 스키마(DB) 및 테이블 이름 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c159faa6-e1a1-4376-aca3-24e7c7bce66d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''SCHEMA_LEVEL = \"bronze\"\n",
    "TABLE_NAME = \"brz_employee_info\"'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d17c9b6-c3fc-4081-ad95-830c15d55c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-3. Azure VM에 올라와있는 PostgreSQL과 연결하는 코드 (VM 켜야 연결 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f983d51-0e15-4650-ae8e-ebee44aea443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''conn = psycopg2.connect(\n",
    "    host=\"20.196.145.211\",\n",
    "    port=5432,\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"asdASD123!@#\"\n",
    ")\n",
    "cur = conn.cursor()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398dfe4a-e20c-4172-aeca-1d6a6825aa74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-4. (필요하면 사용) 특정 테이블 DROP하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282959dc-492c-46c1-9ed9-27947a91e741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 기존 테이블 드롭 (CASCADE 포함)\n",
    "# cur.execute(f\"DROP TABLE IF EXISTS {SCHEMA_LEVEL}.{TABLE_NAME} CASCADE;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc44520e-249d-4c95-ac1e-6ea1b3a04c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-5. 정해진 PostgreSQL 스키마로 테이블을 생성하는 코드(본인 테이블에 맞게 바꾸기, VM 켜서 직접 생성해도 무관)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3607c1de-afda-4c6a-b1ed-6c9dced1af90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cur.execute(f\"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS {SCHEMA_LEVEL}.{TABLE_NAME} (\n",
    "#   id                   varchar(255) NOT NULL PRIMARY KEY,\n",
    "#   sha                  char(40),\n",
    "#   author               varchar(100),\n",
    "#   private              boolean,\n",
    "#   tags                 text ,\n",
    "#   likes                double precision,\n",
    "#   created_at           timestamptz,\n",
    "#   config               text,\n",
    "# );\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085ec367-66aa-416b-ae07-c41cdff95735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-6. Psycopg2의 모든 실행 내역 commit하고 종료하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05562aa1-2278-4e20-8432-5abc951d0bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# conn.commit()\n",
    "# cur.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68fe676d-16c1-4bdf-9083-418214d2b221",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-7. INSERT 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd984b6-b4a3-4204-b2e8-4e23b282d512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def insert_data(\n",
    "    data: Union[pd.DataFrame, pyspark.sql.DataFrame],\n",
    "    schema: str,\n",
    "    table: str,\n",
    "    mode: str = \"overwrite\"\n",
    ") -> None:\n",
    "    # spark 데이터프레임 생성\n",
    "    columns = list(data.columns)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # data = spark.createDataFrame(data, schema=columns)\n",
    "        data = spark.createDataFrame(data)\n",
    "    \n",
    "    # 인증 정보 하드코딩\n",
    "    jdbc_user = \"postgres\"\n",
    "    jdbc_pass = \"asdASD123!@#\"\n",
    "\n",
    "    # 연결 문자열 하드코딩\n",
    "    host = \"20.196.145.211\"\n",
    "    port = \"5432\"\n",
    "    jdbc_url = f\"jdbc:postgresql://{host}:{port}/postgres\"\n",
    "\n",
    "    data.write.format(\"jdbc\").mode(mode).options(\n",
    "        url=jdbc_url,\n",
    "        user=jdbc_user,\n",
    "        password=jdbc_pass,\n",
    "\n",
    "        # 가끔 테이블 이름을 대소문자 혼용하여 인자로 던져주는 경우를 대비한 코드\n",
    "        # PostgreSQL의 테이블은 언제나 소문자만 사용함\n",
    "        dbtable=f\"{schema}.{table.lower()}\",\n",
    "\n",
    "        # overwrite일 때 DROP 후 CREATE가 아니라, TRUNCATE TABLE로 데이터만 비움\n",
    "        truncate=True,\n",
    "\n",
    "        # 대량 적재 튜닝: INSERT할 때 한 번에 몇 행씩 묶어서 넣을지\n",
    "        batchsize=1000,\n",
    "\n",
    "        # 스키마 적재 튜닝: INSERT시 JDBC는 모든 문자열 컬럼에 대해 setString() 함수를 사용해서, 자동으로 PosgreSQL에 text로 적재함\n",
    "        # 이 옵션을 사용하면 unspecified로 넘겨 PostgreSQL 테이블의 스키마를 확인하고, 해당 스키마에 맞게끔 캐스팅함\n",
    "        # 대신 넣으려는 데이터와 테이블의 스키마를 정확히 일치시켜야 함. 그렇지 않으면 에러가 발생함\n",
    "        # 에러가 발생하는 경우 그냥 주석처리하거나, PostgreSQL 테이블 스키마를 TEXT로 전부 바꾸면 해결\n",
    "        stringtype=\"unspecified\"\n",
    "    ).save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b94896-ecdc-4a2c-82e8-79eed50c4adb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-8. (필요하면 사용) 데이터프레임 로드 후 spark 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebe658d-d31d-4211-8162-748db862ad06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 필요하면 그때 사용\n",
    "# # spark dataframe schema 정의\n",
    "# schema = StructType([\n",
    "#     StructField(\"id\",                   StringType(),       False), # PK, NOT NULL\n",
    "#     StructField(\"sha\",                  StringType(),       True),  # CHAR(40)\n",
    "#     StructField(\"author\",               StringType(),       True),  # \n",
    "#     StructField(\"private\",              BooleanType(),      True),  # \n",
    "#     StructField(\"tags\",                 StringType(),       True),  # '[\"a\",\"b\"]' 같은 문자열\n",
    "#     StructField(\"likes\",                IntegerType(),      True),  # \n",
    "#     StructField(\"created_at\",           TimestampType(),    True),  # \n",
    "#     StructField(\"config\",               StringType(),       True),  # JSON 문자열\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "047c6743-3bf5-4310-b137-8def1c1b704b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# csv 로드 후 spark dataframe 생성\n",
    "# path = \"/Workspace/Shared/BRZ_user/brz_employee_info.csv\"\n",
    "# encoding_type = \"UTF-8\"\n",
    "# df = pd.read_csv(path, encoding=encoding_type)\n",
    "\n",
    "# spark_df = spark.createDataFrame(df, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2405b3-c53c-4a05-9a6e-cd55a2d72b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' 필요하다면 여기서 최소한의 전처리 하기 '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 필요하다면 여기서 최소한의 전처리 하기 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d744589c-ba35-4689-816a-5d0e65b31309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0-8. Azure VM의 PostgreSQL에 데이터 적재하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0806703e-2fab-4af0-8a14-8e61417304fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 특정 테이블에 데이터를 삽입하는 코드\n",
    "# mode 종류: overwrite, append, ignore, error\n",
    "# insert_data(\n",
    "#     # data=spark_df,\n",
    "#     data=df,\n",
    "#     schema=SCHEMA_LEVEL,\n",
    "#     table=TABLE_NAME,\n",
    "#     mode=\"overwrite\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbc4429c-034d-4d8f-bf84-d47777526885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## cloud DB에 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99b5131-acce-4d8a-889b-dc123c12bb65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수정된 데이터를 bronze.brz_employee_info 테이블로 저장 완료\n"
     ]
    }
   ],
   "source": [
    "SCHEMA_LEVEL = \"bronze\"\n",
    "TABLE_NAME = \"brz_employee_info\"  # 새 테이블로 저장\n",
    "POSTGRES_CONN = \"postgresql://Drawbridge:asdASD123%21%40%23@cloud-postgredb-server.postgres.database.azure.com:5432/postgres\"\n",
    "engine = create_engine(POSTGRES_CONN, connect_args={\"sslmode\": \"require\"})\n",
    "\n",
    "path = \"/Workspace/Shared/BRZ_user/brz_employee_info.csv\"\n",
    "encoding_type = \"UTF-8\"\n",
    "df = pd.read_csv(path, encoding=encoding_type)\n",
    "\n",
    "df.to_sql(\n",
    "    name=TABLE_NAME,\n",
    "    con=engine,\n",
    "    schema=SCHEMA_LEVEL,\n",
    "    if_exists='replace',  # 기존 테이블 덮어쓰기\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"✅ 수정된 데이터를 {SCHEMA_LEVEL}.{TABLE_NAME} 테이블로 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "250909 구직자 더미 데이터 적재",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}